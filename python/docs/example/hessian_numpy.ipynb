{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuralsens.partial_derivatives as ns\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create synthetic dataset to check behavior of functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 100000\n",
    "n_columns = 8\n",
    "sm = np.random.normal(size=(samples,n_columns))\n",
    "df = pd.DataFrame(sm, columns=['X' + str(x) for x in range(1,n_columns+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check behavior of Hessian function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create output Y as linear function of inputs with some non-linear relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Y'] = - 0.4 * df.X1 ** 3 - 0.5 * df.X2 ** 2 + 0.7 * df.X3 * df.X4 + 0.1 * np.random.normal(size=(samples,)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train MLP model using the data.frame created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create random 80/20 % split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'Y'].to_numpy(), df['Y'], test_size = 0.2, random_state = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0.01, batch_size=10,\n",
       "             hidden_layer_sizes=[10], learning_rate=&#x27;adaptive&#x27;, max_iter=500,\n",
       "             random_state=150, solver=&#x27;sgd&#x27;, tol=0.01, validation_fraction=0.0)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPRegressor</label><div class=\"sk-toggleable__content\"><pre>MLPRegressor(activation=&#x27;logistic&#x27;, alpha=0.01, batch_size=10,\n",
       "             hidden_layer_sizes=[10], learning_rate=&#x27;adaptive&#x27;, max_iter=500,\n",
       "             random_state=150, solver=&#x27;sgd&#x27;, tol=0.01, validation_fraction=0.0)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPRegressor(activation='logistic', alpha=0.01, batch_size=10,\n",
       "             hidden_layer_sizes=[10], learning_rate='adaptive', max_iter=500,\n",
       "             random_state=150, solver='sgd', tol=0.01, validation_fraction=0.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Create MLP model\n",
    "model = MLPRegressor(solver='sgd', # Update function\n",
    "                    hidden_layer_sizes=[10], # #neurons in hidden layers\n",
    "                    learning_rate_init=0.001, # initial learning rate\n",
    "                    activation='logistic', # Logistic sigmoid activation function\n",
    "                    alpha=0.01, # L2 regularization term\n",
    "                    learning_rate='adaptive', # Type of learning rate used in training\n",
    "                    max_iter=500, # Maximum number of iterations\n",
    "                    batch_size=10, # Size of batch when training\n",
    "                    tol=1e-2, # Tolerance for the optimization\n",
    "                    validation_fraction=0.0, # Percentage of samples used for validation\n",
    "                    n_iter_no_change=10, # Maximum number of epochs to not meet tol improvement\n",
    "                    random_state=150)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: R2 0.9545304608269689 MSE 0.1566474580592462\n",
      "Test set: R2 0.9489131534495605 MSE 0.1698521452372367\n"
     ]
    }
   ],
   "source": [
    "# Predict values to check model performance\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Obtain performance metrics\n",
    "print(\"Training set: R2\", r2_score(y_train, y_train_pred), \"MSE\", mean_squared_error(y_train, y_train_pred))\n",
    "print(\"Test set: R2\", r2_score(y_test, y_test_pred), \"MSE\", mean_squared_error(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute hessian function and check sensitivity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain parameters to perform hessian\n",
    "wts = model.coefs_\n",
    "bias = model.intercepts_\n",
    "actfunc = ['identity',model.get_params()['activation'],model.out_activation_]\n",
    "X = pd.DataFrame(X_train, columns=df.columns[df.columns != 'Y'])\n",
    "y = pd.DataFrame(y_train, columns=['Y'])\n",
    "sens_end_layer = 'last'\n",
    "sens_end_input = False\n",
    "sens_origin_layer = 0\n",
    "sens_origin_input = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hessian = ns.hessian_mlp(wts, bias, actfunc, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis of [8, 10, 1] MLP network.\n",
      "\n",
      "Sensitivity measures of each output:\n",
      "\n",
      "$Y \n",
      "\n",
      "metric      mean                                                              \\\n",
      "input         X1        X2        X3        X4        X5        X6        X7   \n",
      "X1      0.018614 -0.001185 -0.002118 -0.000475 -0.001352 -0.002201  0.002742   \n",
      "X2     -0.001185 -0.930347 -0.003779  0.001203 -0.001259  0.000418 -0.000706   \n",
      "X3     -0.002118 -0.003779  0.000500  0.622927 -0.001408 -0.002254  0.001124   \n",
      "X4     -0.000475  0.001203  0.622927  0.001884 -0.000696  0.000677 -0.000856   \n",
      "X5     -0.001352 -0.001259 -0.001408 -0.000696 -0.000348 -0.000192  0.000011   \n",
      "X6     -0.002201  0.000418 -0.002254  0.000677 -0.000192 -0.000102  0.000022   \n",
      "X7      0.002742 -0.000706  0.001124 -0.000856  0.000011  0.000022  0.000017   \n",
      "X8     -0.001394  0.000232 -0.000238  0.000111  0.000111  0.000108 -0.000035   \n",
      "\n",
      "metric                 std            ...                     mean_squared  \\\n",
      "input         X8        X1        X2  ...        X7        X8           X1   \n",
      "X1     -0.001394  2.636354  0.075666  ...  0.003442  0.004134     6.950709   \n",
      "X2      0.000232  0.075666  0.374767  ...  0.001299  0.004843     0.005727   \n",
      "X3     -0.000238  0.083659  0.149933  ...  0.002673  0.002750     0.007003   \n",
      "X4      0.000111  0.085108  0.150502  ...  0.002686  0.002790     0.007244   \n",
      "X5      0.000111  0.004030  0.008338  ...  0.000042  0.000086     0.000018   \n",
      "X6      0.000108  0.003552  0.004115  ...  0.000028  0.000052     0.000017   \n",
      "X7     -0.000035  0.003442  0.001299  ...  0.000021  0.000016     0.000019   \n",
      "X8     -0.000057  0.004134  0.004843  ...  0.000016  0.000047     0.000019   \n",
      "\n",
      "metric                                                            \\\n",
      "input         X2        X3        X4            X5            X6   \n",
      "X1      0.005727  0.007003  0.007244  1.807183e-05  1.745878e-05   \n",
      "X2      1.005997  0.022494  0.022652  7.110853e-05  1.710756e-05   \n",
      "X3      0.022494  0.052427  0.439725  2.906977e-05  1.817044e-05   \n",
      "X4      0.022652  0.439725  0.053419  2.712167e-05  1.352828e-05   \n",
      "X5      0.000071  0.000029  0.000027  1.707065e-07  5.787309e-08   \n",
      "X6      0.000017  0.000018  0.000014  5.787309e-08  2.146667e-08   \n",
      "X7      0.000002  0.000008  0.000008  1.933706e-09  1.280602e-09   \n",
      "X8      0.000024  0.000008  0.000008  1.972256e-08  1.430960e-08   \n",
      "\n",
      "metric                              \n",
      "input             X7            X8  \n",
      "X1      1.936558e-05  1.903357e-05  \n",
      "X2      2.186254e-06  2.350995e-05  \n",
      "X3      8.406032e-06  7.620761e-06  \n",
      "X4      7.946235e-06  7.796377e-06  \n",
      "X5      1.933706e-09  1.972256e-08  \n",
      "X6      1.280602e-09  1.430960e-08  \n",
      "X7      7.063833e-10  1.461006e-09  \n",
      "X8      1.461006e-09  5.449186e-09  \n",
      "\n",
      "[8 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check sensitivity metrics\n",
    "# For X1, X5 mean and std should be around 0\n",
    "# For X2, mean should be around -1\n",
    "# For X3, X4, mean should be around 0.7\n",
    "hessian.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis of [8, 10, 1] MLP network.\n",
      "\n",
      "80000 samples\n",
      "\n",
      "Sensitivities of each output (only 5 first samples):\n",
      "\n",
      "$Y \n",
      "\n",
      "input        X1                                                              \\\n",
      "input        X1        X2        X3        X4        X5        X6        X7   \n",
      "0      1.420800  0.039983 -0.117257  0.096633 -0.000918 -0.004460  0.003808   \n",
      "1     -4.907888 -0.108965  0.016810 -0.034772  0.000626 -0.001111  0.003403   \n",
      "2     -0.122712 -0.067455 -0.028222  0.082976 -0.005913 -0.004727  0.001736   \n",
      "3      0.917230 -0.071788  0.145817 -0.140794 -0.003081 -0.004947  0.002342   \n",
      "4      0.839122 -0.026569 -0.020253 -0.009926 -0.002104 -0.004192  0.002447   \n",
      "\n",
      "input                  X2            ...        X7                  X8  \\\n",
      "input        X8        X1        X2  ...        X7        X8        X1   \n",
      "0     -0.001607  0.039983 -0.908404  ...  0.000012 -0.000031 -0.001607   \n",
      "1     -0.008674 -0.108965 -1.372393  ... -0.000001 -0.000046 -0.008674   \n",
      "2      0.000823 -0.067455 -1.229366  ...  0.000021 -0.000059  0.000823   \n",
      "3      0.001203 -0.071788 -1.060841  ... -0.000003 -0.000021  0.001203   \n",
      "4     -0.000342 -0.026569 -0.788495  ...  0.000019 -0.000038 -0.000342   \n",
      "\n",
      "input                                                                        \n",
      "input        X2        X3        X4        X5        X6        X7        X8  \n",
      "0      0.000300  0.001581  0.000394  0.000056  0.000071 -0.000031 -0.000004  \n",
      "1     -0.006917 -0.001827  0.003293  0.000326  0.000221 -0.000046 -0.000166  \n",
      "2     -0.006954 -0.003892 -0.002872  0.000261  0.000179 -0.000059 -0.000082  \n",
      "3     -0.002161 -0.002231  0.001871  0.000193  0.000169 -0.000021 -0.000142  \n",
      "4     -0.001773  0.000836  0.001672  0.000121  0.000109 -0.000038 -0.000045  \n",
      "\n",
      "[5 rows x 64 columns]\n"
     ]
    }
   ],
   "source": [
    "hessian.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('neuralsens')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6293a8b2c86d9a52e3a722d726ae162a9dda2b649303347e21b2798b86287157"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
